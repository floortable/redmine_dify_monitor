#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import json
import logging
import time
from datetime import datetime, timezone
from dateutil import parser
import os
import re
from logging.handlers import RotatingFileHandler
import traceback
import signal
import sys
import sqlite3

# --- è¨­å®š ---
REDMINE_URL = os.getenv("REDMINE_URL", "http://localhost:3000")
REDMINE_API_KEY = os.getenv("REDMINE_API_KEY", "your_redmine_api_key")

DIFY_API_URL = os.getenv("DIFY_API_URL", "http://localhost:5001/v1/workflows/execute")
DIFY_API_KEY = os.getenv("DIFY_API_KEY", "your_dify_api_key")

TEAMS_WEBHOOK_URL = os.getenv("TEAMS_WEBHOOK_URL", "https://graph.microsoft.com/...")
TEAMS_WEBHOOK_SECONDARY_URL = os.getenv("TEAMS_WEBHOOK_SECONDARY_URL", "")

POLL_INTERVAL = int(os.getenv("POLL_INTERVAL", "60"))  # ç§’å˜ä½
STATE_DB = "/var/lib/redmine_dify_monitor/processed_issues.db"
LOG_FILE = "/var/log/redmine_dify_monitor/redmine_dify_monitor.log"
os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)
os.makedirs(os.path.dirname(STATE_DB), exist_ok=True)
LOG_LEVEL_NAME = os.getenv("LOG_LEVEL", "INFO").upper()
try:
    LOG_LEVEL = getattr(logging, LOG_LEVEL_NAME)
    if not isinstance(LOG_LEVEL, int):
        raise AttributeError
    _LOG_LEVEL_INVALID = False
except AttributeError:
    LOG_LEVEL = logging.INFO
    _LOG_LEVEL_INVALID = LOG_LEVEL_NAME != "INFO"

logging.basicConfig(
    level=LOG_LEVEL,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        RotatingFileHandler(LOG_FILE, maxBytes=5*1024*1024, backupCount=3, encoding="utf-8"),
        logging.StreamHandler()  # â† docker logs ã«å‡ºã™
    ]
)
if _LOG_LEVEL_INVALID:
    logging.warning(f"LOG_LEVEL '{LOG_LEVEL_NAME}' ã¯ä¸æ­£ã§ã™ã€‚INFO ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
logging.info(f"ãƒ­ã‚°åˆæœŸåŒ–å®Œäº†ï¼ (LOG_LEVEL={logging.getLevelName(LOG_LEVEL)})")

# --- çŠ¶æ…‹ãƒ­ãƒ¼ãƒ‰/ä¿å­˜ ---
def init_state_db():
    try:
        with sqlite3.connect(STATE_DB) as conn:
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS processed_issues (
                    issue_id TEXT PRIMARY KEY,
                    updated_on TEXT NOT NULL,
                    last_seen_at TEXT DEFAULT (strftime('%Y-%m-%dT%H:%M:%SZ','now'))
                )
                """
            )
    except sqlite3.Error as e:
        logging.error(f"çŠ¶æ…‹DBåˆæœŸåŒ–å¤±æ•—: {e}")
        raise

def load_processed_issues():
    try:
        init_state_db()
    except Exception:
        return {}

    try:
        with sqlite3.connect(STATE_DB) as conn:
            cursor = conn.execute("SELECT issue_id, updated_on FROM processed_issues")
            return {issue_id: updated_on for issue_id, updated_on in cursor.fetchall()}
    except sqlite3.Error as e:
        logging.error(f"çŠ¶æ…‹DBèª­ã¿è¾¼ã¿å¤±æ•—: {e}")
        return {}

def upsert_processed_issue(issue_id, updated_on):
    try:
        with sqlite3.connect(STATE_DB) as conn:
            conn.execute(
                """
                INSERT INTO processed_issues (issue_id, updated_on, last_seen_at)
                VALUES (?, ?, strftime('%Y-%m-%dT%H:%M:%SZ','now'))
                ON CONFLICT(issue_id) DO UPDATE SET
                    updated_on=excluded.updated_on,
                    last_seen_at=strftime('%Y-%m-%dT%H:%M:%SZ','now')
                """,
                (str(issue_id), updated_on),
            )
            conn.commit()
    except sqlite3.Error as e:
        logging.error(f"çŠ¶æ…‹DBæ›´æ–°å¤±æ•—(issue_id={issue_id}): {e}")

# --- ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å¯¾å¿œ ---
def normalize_timestamp(ts):
    try:
        return parser.parse(ts).astimezone(timezone.utc).isoformat()
    except Exception:
        return ts
    
# --- Redmine ãƒã‚±ãƒƒãƒˆå–å¾— ---
def get_recent_issues():
    params = {"key": REDMINE_API_KEY, "status_id": "*", "sort": "updated_on:desc", "limit": 10}
    for attempt in range(2):
        try:
            resp = requests.get(f"{REDMINE_URL}/issues.json", params=params, timeout=30)
            resp.raise_for_status()
            return resp.json().get("issues", [])
        except (requests.exceptions.RequestException, ValueError) as e:
            wait = 4 ** attempt
            logging.warning(f"Redmineå–å¾—å¤±æ•—({attempt+1}/2): {e}")
            time.sleep(wait)
    return []

# --- Redmine å·®ã—æˆ»ã—ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«æ›´æ–° ---
def update_redmine_status(issue_id, status_id):
    url = f"{REDMINE_URL}/issues/{issue_id}.json"
    payload = {"issue": {"status_id": status_id}}
    headers = {"X-Redmine-API-Key": REDMINE_API_KEY, "Content-Type": "application/json"}
    try:
        requests.put(url, headers=headers, json=payload, timeout=10).raise_for_status()
        logging.info(f"Redmineãƒã‚±ãƒƒãƒˆ #{issue_id} ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        logging.error(f"Redmineã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°å¤±æ•—: {e}")

# --- Dify å¿œç­”ãƒ‡ã‚³ãƒ¼ãƒ‰ ---
def safe_decode_dify_text(text: str) -> str:
    # ã‚‚ã— \x?? ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå«ã¾ã‚Œã¦ã„ãŸã‚‰ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—è§£é™¤ã‚’è©¦ã¿ã‚‹
    if "\\x" in text:
        try:
            return text.encode("latin-1").decode("unicode_escape").encode("latin-1").decode("utf-8")
        except Exception:
            pass  # å¤±æ•—ã—ãŸã‚‰ãã®ã¾ã¾è¿”ã™
    return text

# --- Dify å‘¼ã³å‡ºã— ---
def call_dify(ticket_id):
    DIFY_HEADERS = {"Authorization": f"Bearer {DIFY_API_KEY}", "Content-Type": "application/json"}
    payload = {"inputs": {"ticketid": ticket_id, "LLM": "GPT"}, "response_mode": "blocking", "user": "redmine-monitor"}

    logging.debug(f"Difyå‘¼ã³å‡ºã—é–‹å§‹ URL={DIFY_API_URL}")
    logging.debug(f"Difyãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€: {json.dumps(DIFY_HEADERS, ensure_ascii=False, indent=2)}")
    logging.debug(f"Difyãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒšã‚¤ãƒ­ãƒ¼ãƒ‰: {json.dumps(payload, ensure_ascii=False, indent=2)}")

    try:
        resp = requests.post(DIFY_API_URL, headers=DIFY_HEADERS, json=payload, timeout=360)
        resp.raise_for_status()
        try:
            data = resp.json()
            logging.debug(f"Difyå¿œç­”(JSON): {json.dumps(data, ensure_ascii=False, indent=2)}")
        except json.JSONDecodeError:
            logging.error(f"Difyå¿œç­”ãŒJSONã¨ã—ã¦è§£é‡ˆã§ãã¾ã›ã‚“: {resp.text[:200]}")
            return None, None
    except Exception as e:
        logging.error(f"Difyå‘¼ã³å‡ºã—å¤±æ•—: {e}")
        return None, None

    try:
        raw_outputs = data.get("data", {}).get("outputs", "")
        if isinstance(raw_outputs, str):
            try:
                outputs = json.loads(raw_outputs)
            except Exception:
                # ãƒ€ãƒ–ãƒ«JSONã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¯¾ç­–
                try:
                    outputs = json.loads(json.loads(raw_outputs))
                except Exception:
                    outputs = {}
        elif isinstance(raw_outputs, dict):
            outputs = raw_outputs
        else:
            outputs = {}

        status = outputs.get("status")
        if status and status != "ok":
            if status == "caseid_mismatch":
                logging.warning(f"Difyå¿œç­”ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒcaseid_mismatch: ãƒã‚±ãƒƒãƒˆID={ticket_id}")
            else:
                logging.info(f"Difyå¿œç­”ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒéOKã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: status={status}")
            return None, status

        text = outputs.get("text") or outputs.get("text_1") or outputs.get("gpt") or outputs.get("gemma") or ""
        if not text:
            return None, status

        decoded = safe_decode_dify_text(text)
        cleaned = decoded.strip()

        # --- ğŸš« ç„¡åŠ¹ãªå¿œç­”ã‚’é™¤å¤– ---
        if not cleaned or cleaned in ["", "null", "None"] or re.fullmatch(r"\d+", cleaned):
            logging.info(f"Difyå¿œç­”ãŒç„¡åŠ¹ã¾ãŸã¯æ•°å­—ã®ã¿ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {repr(cleaned)}")
            return None, status

        return cleaned, status or "ok"
    
    except Exception as e:
        logging.error(f"Difyå¿œç­”è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None, None
    
# --- Difyçµæœè§£æ ---
def parse_dify_result(text):
    logging.debug("=== parse_dify_result é–‹å§‹ ===")

    # ãƒã‚¤ãƒˆåˆ—ï¼ˆ\xE6å½¢å¼ï¼‰ã§æ¸¡ã•ã‚Œã‚‹ã‚±ãƒ¼ã‚¹ã¸ã®å¯¾å¿œ
    if isinstance(text, (bytes, bytearray)):
        try:
            text = text.decode("utf-8", errors="replace")
            logging.debug("textã‚’UTF-8ã¨ã—ã¦ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            logging.debug(f"textã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")

    # None ã‚„ç©ºæ–‡å­—å¯¾ç­–
    if not text or str(text).strip() in ["", "null", "None"]:
        logging.debug(f"textãŒç©ºã¾ãŸã¯ä¸æ­£: {repr(text)}")
        logging.debug("=== parse_dify_result çµæœ: ä¸æ˜ ===")
        return "ä¸æ˜"

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€æ—¦ãƒ­ã‚°ã«å‡ºã—ã¦ç¢ºèª
    logging.debug(f"Difyå¿œç­”æœ¬æ–‡: {repr(text[:300])}")  # é•·æ–‡ã®å ´åˆã¯å…ˆé ­300æ–‡å­—ã®ã¿å‡ºã™

    if not text or text.strip() in ["", "null", "None"] or re.fullmatch(r"\d+", text.strip()):
        logging.info("Difyå¿œç­”ãŒç©ºã¾ãŸã¯æ•°å­—ã®ã¿ã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        logging.debug("=== parse_dify_result çµæœ: None ===")
        return None
    m_result = re.search(r"(æŸ»é–²çµæœ|çµæœ)[:ï¼š]\s*(æ‰¿èª|å´ä¸‹)", text)
    m_reason = re.search(r"(ç†ç”±|åŸå› )[:ï¼š]\s*(.+)", text)
    logging.debug(f"m_result: {m_result.group(0) if m_result else 'None'}")
    logging.debug(f"m_reason: {m_reason.group(0) if m_reason else 'None'}")

    if not m_result:
        logging.debug("æŸ»é–²çµæœã®æ­£è¦è¡¨ç¾ã«ãƒãƒƒãƒã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
        logging.debug("=== parse_dify_result çµæœ: ä¸æ˜ ===")
        return {"æŸ»é–²çµæœ": "ä¸æ˜", "ç†ç”±": "åˆ¤å®šãªã—"}

    result = m_result.group(2)
    reason = m_reason.group(2).strip() if m_reason else "ç†ç”±ãªã—"

    logging.debug(f"æŠ½å‡ºçµæœ â†’ æŸ»é–²çµæœ: {result}, ç†ç”±: {reason}")
    logging.debug("=== parse_dify_result æ­£å¸¸çµ‚äº† ===")

    return {"æŸ»é–²çµæœ": m_result.group(2), "ç†ç”±": m_reason.group(2).strip() if m_reason else "ç†ç”±ãªã—"}

# --- TeamsæŠ•ç¨¿ ---
def post_to_teams(issue, result):
    """Adaptive Cardã‚’Teamsã«æŠ•ç¨¿"""
    ticket_id = issue["id"]
    subject = issue["subject"]
    m_result = result["æŸ»é–²çµæœ"]
    m_reason = result["ç†ç”±"]

    # ãƒ¡ã‚¤ãƒ³Webhook
    webhooks = [TEAMS_WEBHOOK_URL]

    # å´ä¸‹æ™‚ã®ã¿è¿½åŠ ã®é€šçŸ¥å…ˆã‚‚è¨­å®š
    if m_result == "å´ä¸‹" and TEAMS_WEBHOOK_SECONDARY_URL:
        webhooks.append(TEAMS_WEBHOOK_SECONDARY_URL)

    # ãƒ‡ã‚¶ã‚¤ãƒ³è¨­å®š
    if m_result == "å´ä¸‹":
        color = "Attention"
        accent_color = "#D13438"  # èµ¤
        emoji = "âŒ"
        bg_style = {
            "type": "Container",
            "items": [
                {"type": "TextBlock", "text": f"{emoji} **ãƒã‚±ãƒƒãƒˆå´ä¸‹**", "size": "Large", "weight": "Bolder", "color": "Attention"},
                {"type": "TextBlock", "text": f"[Redmine ãƒã‚±ãƒƒãƒˆ #{ticket_id}]({REDMINE_URL}/issues/{ticket_id})", "wrap": True, "spacing": "Small"},
                {"type": "TextBlock", "text": f"ä»¶åï¼š{subject}", "wrap": True, "spacing": "Small"},
                {
                    "type": "Container",
                    "style": "emphasis",
                    "items": [
                        {"type": "TextBlock", "text": "å´ä¸‹ç†ç”±", "weight": "Bolder", "color": "Attention"},
                        {"type": "TextBlock", "text": m_reason, "wrap": True, "spacing": "Small"},
                    ],
                    "bleed": True
                }
            ],
            "bleed": True
        }
    elif m_result == "æ‰¿èª":
        color = "Good"
        accent_color = "#107C10"
        emoji = "âœ…"
        bg_style = {
            "type": "Container",
            "items": [
                {"type": "TextBlock", "text": f"{emoji} **ãƒã‚±ãƒƒãƒˆæ‰¿èª**", "size": "Large", "weight": "Bolder", "color": "Good"},
                {"type": "TextBlock", "text": f"Redmine ãƒã‚±ãƒƒãƒˆ #{ticket_id}", "wrap": True, "spacing": "Small"},
                {"type": "TextBlock", "text": f"ä»¶åï¼š{subject}", "wrap": True, "spacing": "Small"},
                {"type": "TextBlock", "text": f"ç†ç”±ï¼š{m_reason}", "wrap": True, "spacing": "Small"},
            ],
            "bleed": True
        }
    else:
        color = "Default"
        accent_color = "#767676"
        emoji = "â”"
        bg_style = {
            "type": "Container",
            "items": [
                {"type": "TextBlock", "text": f"{emoji} åˆ¤å®šä¸æ˜", "size": "Large", "weight": "Bolder"},
                {"type": "TextBlock", "text": f"[Redmine ãƒã‚±ãƒƒãƒˆ #{ticket_id}]({REDMINE_URL}/issues/{ticket_id})", "wrap": True, "spacing": "Small"},
                {"type": "TextBlock", "text": f"ä»¶åï¼š{subject}", "wrap": True},
            ]
        }

    # AdaptiveCardæœ¬ä½“
    card = {
        "type": "message",
        "attachments": [{
            "contentType": "application/vnd.microsoft.card.adaptive",
            "content": {
                "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
                "type": "AdaptiveCard",
                "version": "1.4",
                "body": [bg_style],
            }
        }]
    }

    # ğŸ” DEBUG ãƒ­ã‚°ã«å‡ºåŠ›
    logging.debug(f"é€ä¿¡ã‚«ãƒ¼ãƒ‰å†…å®¹:\n{json.dumps(card, ensure_ascii=False, indent=2)}")

    # è¤‡æ•°Webhookã«é€ä¿¡
    for webhook in webhooks:
        for attempt in range(3):
            try:
                resp = requests.post(webhook, json=card, timeout=10)
                resp.raise_for_status()
                logging.info(f"Teamsé€ä¿¡æˆåŠŸ ({m_result}) â†’ {webhook}")
                break
            except Exception as e:
                wait = 2 ** attempt
                logging.warning(f"Teamsé€ä¿¡å¤±æ•—({attempt+1}/3): {e}")
                time.sleep(wait)

def post_caseid_mismatch_alert(issue):
    """caseidãŒä¸€è‡´ã—ãªã„å ´åˆã®é«˜å„ªå…ˆåº¦ã‚¢ãƒ©ãƒ¼ãƒˆ"""
    ticket_id = issue["id"]
    subject = issue["subject"]
    webhooks = [TEAMS_WEBHOOK_URL]
    if TEAMS_WEBHOOK_SECONDARY_URL:
        webhooks.append(TEAMS_WEBHOOK_SECONDARY_URL)

    card = {
        "type": "message",
        "attachments": [{
            "contentType": "application/vnd.microsoft.card.adaptive",
            "content": {
                "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
                "type": "AdaptiveCard",
                "version": "1.4",
                "body": [
                    {
                        "type": "Container",
                        "style": "attention",
                        "bleed": True,
                        "items": [
                            {
                                "type": "TextBlock",
                                "text": "ğŸš¨ å—ä»˜ç•ªå·ä¸ä¸€è‡´ã®å¯èƒ½æ€§",
                                "size": "Large",
                                "weight": "Bolder",
                                "color": "Attention"
                            },
                            {
                                "type": "TextBlock",
                                "text": f"[Redmine ãƒã‚±ãƒƒãƒˆ #{ticket_id}]({REDMINE_URL}/issues/{ticket_id})",
                                "wrap": True,
                                "spacing": "Small"
                            },
                            {
                                "type": "TextBlock",
                                "text": f"ä»¶åï¼š{subject}",
                                "wrap": True,
                                "spacing": "Small"
                            },
                            {
                                "type": "TextBlock",
                                "text": "DifyãŒ caseid mismatch ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸã€‚ç•°ãªã‚‹å—ä»˜ç•ªå·ã¸ã®å›ç­”ãŒç”³å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚è‡³æ€¥ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                                "wrap": True,
                                "spacing": "Medium",
                                "color": "Attention"
                            }
                        ]
                    }
                ]
            }
        }]
    }

    logging.debug(f"caseid mismatch ã‚¢ãƒ©ãƒ¼ãƒˆã‚«ãƒ¼ãƒ‰:\n{json.dumps(card, ensure_ascii=False, indent=2)}")

    for webhook in webhooks:
        for attempt in range(3):
            try:
                resp = requests.post(webhook, json=card, timeout=10)
                resp.raise_for_status()
                logging.info(f"Teamsé€ä¿¡æˆåŠŸ (caseid_mismatch) â†’ {webhook}")
                break
            except Exception as e:
                wait = 2 ** attempt
                logging.warning(f"Teamsé€ä¿¡å¤±æ•—(caseid_mismatch {attempt+1}/3): {e}")
                time.sleep(wait)

# --- SIGTERMå¯¾å¿œ ---
def handle_shutdown(signum, frame):
    logging.info(f"åœæ­¢ã‚·ã‚°ãƒŠãƒ«({signum})ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚çµ‚äº†ã—ã¾ã™ã€‚")
    sys.exit(0)

# --- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— ---
def main():
    processed = load_processed_issues()

    while True:
        try:
            issues = get_recent_issues()
            for issue in issues:
                issue_id = issue["id"]
                updated_on = issue["updated_on"]
                subject = issue["subject"]

                updated_on = normalize_timestamp(issue["updated_on"])
                last_time = processed.get(str(issue_id))
                if last_time == updated_on:
                    continue  # å¤‰æ›´ãªã— â†’ ã‚¹ã‚­ãƒƒãƒ—

                logging.info(f"ğŸ†• å‡¦ç†å¯¾è±¡ãƒã‚±ãƒƒãƒˆ: #{issue_id} ({subject}) â†’ Difyè§£æé–‹å§‹")
                result_text, dify_status = call_dify(issue_id)
                if dify_status == "caseid_mismatch":
                    logging.warning(f"caseid mismatch æ¤œçŸ¥: ãƒã‚±ãƒƒãƒˆ #{issue_id} ({subject})")
                    post_caseid_mismatch_alert(issue)
                    processed[str(issue_id)] = updated_on
                    upsert_processed_issue(issue_id, updated_on)
                    continue
                if dify_status and dify_status != "ok":
                    processed[str(issue_id)] = updated_on
                    upsert_processed_issue(issue_id, updated_on)
                    continue
                if not result_text:
                    logging.info("Difyå¿œç­”ãªã—ã€ã‚¹ã‚­ãƒƒãƒ—")
                    processed[str(issue_id)] = updated_on
                    upsert_processed_issue(issue_id, updated_on)
                    continue

                #if result and result["æŸ»é–²çµæœ"] == "å´ä¸‹":
                #    update_redmine_status(issue_id, 5)  # â€œå·®ã—æˆ»ã—â€ ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹IDã«ç½®ãæ›ãˆ

                result = parse_dify_result(result_text)
                if result and result["æŸ»é–²çµæœ"] != "ä¸æ˜":
                    post_to_teams(issue, result)
                    logging.info(f"Teamsã«æŠ•ç¨¿: {result['æŸ»é–²çµæœ']} ({subject})")

                # æ›´æ–°æ™‚åˆ»ã‚’è¨˜éŒ²
                processed[str(issue_id)] = updated_on
                upsert_processed_issue(issue_id, updated_on)

        except Exception as e:
            logging.error(f"ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}\n{traceback.format_exc()}")

        time.sleep(POLL_INTERVAL)

if __name__ == "__main__":
    signal.signal(signal.SIGTERM, handle_shutdown)
    try:
        main()
    except KeyboardInterrupt:
        logging.info("åœæ­¢è¦æ±‚ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        exit(0)
